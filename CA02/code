CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. 

In this assignment you will ...
1. Complete the code such a way that it works correctly with this given parts of the program.
2. Explain as clearly as possible what each part of the code is doing. Use "Markdown" texts and code commenting to explain the code

IMPORTANT NOTE:

The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy.

pip install scikit-learn

pip install scipy

import os
import numpy as np
from collections import Counter

# Import all other necessary libraries. Your code below ...
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

#CLEANING AND PREPARING DATA

#1 - Constructing a dictionary for all words
#2 - Removing items that are not an alphabetic words or items that are a single letter word
#3 - Transforming the dictionary into a list of most common 3000 words

def make_Dictionary(root_dir):
  all_words = []
  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]
  for mail in emails:
    with open(mail) as m:
      for line in m:
        words = line.split()
        all_words += words
  dictionary = Counter(all_words)
  list_to_remove = list(dictionary)
  for item in list_to_remove:
    #Removing if not alphabetical
    if item.isalpha() == False:
      del dictionary[item]
    #Removing if a single letter word
    elif len(item) == 1:
      del dictionary[item]
    #Transforming the dictionary into a list of most common 3000 words
  dictionary = dictionary.most_common(3000)
  return dictionary
            

#Creating a label and word frequency matrix using dictionary

#The code is performing the following operations:
    # - Extracting the third line of the file
    # - Splitting the line into individual words
    # - Counting the frequency of each word in the line and updating the features_matrix array accordingly
    # - Determining if the email is spam (label 1) or not (label 0) based on the name of the file
    # - Updating the train_labels array with the label determined in the previous step

def extract_features(mail_dir):
  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]
  features_matrix = np.zeros((len(files),3000))
  train_labels = np.zeros(len(files))
  count = 1;
  docID = 0;
  for fil in files:
    with open(fil) as fi:
      for i, line in enumerate(fi):
        if i ==2:
          words = line.split()
          for word in words:
            wordID = 0
            for i, d in enumerate(dictionary):
              if d[0] == word:
                wordID = i
                features_matrix[docID,wordID] = words.count(word)
      train_labels[docID] = 0;
      filepathTokens = fil.split('/')
      lastToken = filepathTokens[len(filepathTokens)-1]
      if lastToken.startswith("spmsg"):
        train_labels[docID] = 1;
        count = count + 1
      docID = docID + 1
  return features_matrix, train_labels                

# Enter the "path" of your "train_mails" and "test-mails" FOLDERS in this cell ...
# for example: TRAIN_DIR = '../../train-mails'
#              TEST_DIR = '../../test-mails'

#Defining TRAIN_DIR variable and assigning it a string value with the file path to a directory on a file
#system that contains email files for training. The variable TRAIN_DIR contains training data.
TRAIN_DIR = "Data/train-mails"

#Defining TEST_DIR variable and assigning it a string value with the file path to a directory on a file
#system that contains email files for testing. The variable TEST_DIR contains testing data.
TEST_DIR = "Data/test-mails"
TRAIN_DIR = "Data/train-mails"

#Defining a new variable (dictionary) and with make_Dictionary function creating a dictionary of words from
#emails in the TRAIN_DIR file
dictionary = make_Dictionary(TRAIN_DIR)

print("reading and processing emails from TRAIN and TEST folders")

#Creating features_matrix and test_features_matrix variables that store the frequency of each unique word in each
#email file and labels and test_labels variables that store the label (spam or not spam) of each email file.
#Done for train and test data separately
features_matrix, labels = extract_features(TRAIN_DIR)
test_features_matrix, test_labels = extract_features(TEST_DIR)

#TRAINING THE MODEL

# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate
#PERFORMANCE (Accuracy)

# Code below ...

print("reading and processing emails from TRAIN and TEST folders")

#implementing the Gaussian Naive Bayes algorithm for classification
#GaussianNB is used in classification and it assumes that features follow a normal distribution
print ("Training Model using Gaussian Naive Bayes algorithm .....")
model = GaussianNB()
print ("Training completed")

#training the model
model.fit(features_matrix, labels)

#predicting
print ("testing trained model to predict Test Data labels")
predicted_labels = model.predict(test_features_matrix)
print ("Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:")

#evaluating performance (accuracy) - comparing the accuracy score for predicted labels (accuracy is a percentage of
#correct predictions that our model got right)
print(accuracy_score(test_labels, predicted_labels))

# Your output should look like below if your code is right

======================= END OF PROGRAM =========================
